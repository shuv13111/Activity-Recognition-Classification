{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628512d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading our files\n",
    "\n",
    "x = pd.read_csv('processed_predictors.csv')\n",
    "y = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d00b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036323</td>\n",
       "      <td>-0.507420</td>\n",
       "      <td>1.551777</td>\n",
       "      <td>-0.658797</td>\n",
       "      <td>2.620898</td>\n",
       "      <td>-0.201656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.036323</td>\n",
       "      <td>-0.507420</td>\n",
       "      <td>1.597951</td>\n",
       "      <td>-0.920315</td>\n",
       "      <td>2.510088</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.036323</td>\n",
       "      <td>-0.507420</td>\n",
       "      <td>1.644125</td>\n",
       "      <td>-0.658797</td>\n",
       "      <td>2.510088</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.076021</td>\n",
       "      <td>-0.473364</td>\n",
       "      <td>1.597951</td>\n",
       "      <td>-0.488506</td>\n",
       "      <td>2.510088</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.076021</td>\n",
       "      <td>-0.473364</td>\n",
       "      <td>1.782646</td>\n",
       "      <td>-0.920315</td>\n",
       "      <td>2.510088</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41752</th>\n",
       "      <td>41752</td>\n",
       "      <td>-1.194322</td>\n",
       "      <td>0.090995</td>\n",
       "      <td>-0.341343</td>\n",
       "      <td>1.025865</td>\n",
       "      <td>-0.260180</td>\n",
       "      <td>1.709865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41753</th>\n",
       "      <td>41753</td>\n",
       "      <td>-1.856489</td>\n",
       "      <td>-0.108477</td>\n",
       "      <td>-0.557436</td>\n",
       "      <td>-0.348625</td>\n",
       "      <td>0.589369</td>\n",
       "      <td>1.442008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41754</th>\n",
       "      <td>41754</td>\n",
       "      <td>-0.193927</td>\n",
       "      <td>3.019820</td>\n",
       "      <td>-0.027362</td>\n",
       "      <td>0.587974</td>\n",
       "      <td>0.183063</td>\n",
       "      <td>-0.487776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41755</th>\n",
       "      <td>41755</td>\n",
       "      <td>-0.837038</td>\n",
       "      <td>-0.084151</td>\n",
       "      <td>0.258914</td>\n",
       "      <td>2.248309</td>\n",
       "      <td>0.072252</td>\n",
       "      <td>0.644527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41756</th>\n",
       "      <td>41756</td>\n",
       "      <td>-1.008535</td>\n",
       "      <td>0.786712</td>\n",
       "      <td>0.798223</td>\n",
       "      <td>-0.634470</td>\n",
       "      <td>-0.297117</td>\n",
       "      <td>0.930646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41757 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0               0   0.036323  -0.507420   1.551777  -0.658797   2.620898   \n",
       "1               1   0.036323  -0.507420   1.597951  -0.920315   2.510088   \n",
       "2               2   0.036323  -0.507420   1.644125  -0.658797   2.510088   \n",
       "3               3   0.076021  -0.473364   1.597951  -0.488506   2.510088   \n",
       "4               4   0.076021  -0.473364   1.782646  -0.920315   2.510088   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "41752       41752  -1.194322   0.090995  -0.341343   1.025865  -0.260180   \n",
       "41753       41753  -1.856489  -0.108477  -0.557436  -0.348625   0.589369   \n",
       "41754       41754  -0.193927   3.019820  -0.027362   0.587974   0.183063   \n",
       "41755       41755  -0.837038  -0.084151   0.258914   2.248309   0.072252   \n",
       "41756       41756  -1.008535   0.786712   0.798223  -0.634470  -0.297117   \n",
       "\n",
       "       var_rss23  \n",
       "0      -0.201656  \n",
       "1      -0.993051  \n",
       "2      -0.993051  \n",
       "3      -0.993051  \n",
       "4      -0.993051  \n",
       "...          ...  \n",
       "41752   1.709865  \n",
       "41753   1.442008  \n",
       "41754  -0.487776  \n",
       "41755   0.644527  \n",
       "41756   0.930646  \n",
       "\n",
       "[41757 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c332c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the indices column\n",
    "\n",
    "x.drop(x.columns[0], inplace = True, axis = 1)\n",
    "y.drop(y.columns[0], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1853434",
   "metadata": {},
   "source": [
    "## Since, we will be running RandomSearchCV along with GridSearchCV on our dataset, it will require heavy computation. To minimize the computation time, lets randomly sample 10,000 observations and proceed with modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5aa50b",
   "metadata": {},
   "source": [
    "### To do random sampling, I am merging X and Y and sample ramndomly. I will segregate this post sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49d2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([x,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d3d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8b25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_sampled.drop('label', axis = 1)\n",
    "y = df_sampled.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26341b27",
   "metadata": {},
   "source": [
    "## Looking at the distribution of our target variable, there is an evidence of imbalance, hence we will address this during our model performance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38620dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cycling     1745\n",
       "sitting     1725\n",
       "walking     1709\n",
       "lying       1705\n",
       "standing    1685\n",
       "bending1     851\n",
       "bending2     580\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac082f9",
   "metadata": {},
   "source": [
    "## There are 2 classes, bending1 and bending2 which are similar, lets call them bending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ab114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.apply(lambda x: 'bending' if x == 'bending1' or x == 'bending2' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9af2625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cycling     1745\n",
       "sitting     1725\n",
       "walking     1709\n",
       "lying       1705\n",
       "standing    1685\n",
       "bending     1431\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720f87b",
   "metadata": {},
   "source": [
    "## There is a hint of slight imbalance. Since it is SLIGHT, I am ignoring it. However, if it was not slight, I would have balanced the training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c79b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6d28b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24147</th>\n",
       "      <td>0.949382</td>\n",
       "      <td>-0.716622</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>-0.616225</td>\n",
       "      <td>0.737116</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19820</th>\n",
       "      <td>0.552400</td>\n",
       "      <td>-0.473364</td>\n",
       "      <td>-1.818901</td>\n",
       "      <td>-0.008043</td>\n",
       "      <td>-1.922341</td>\n",
       "      <td>0.224479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>0.076021</td>\n",
       "      <td>-0.473364</td>\n",
       "      <td>-0.433691</td>\n",
       "      <td>-0.920315</td>\n",
       "      <td>-1.527855</td>\n",
       "      <td>-0.420812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40020</th>\n",
       "      <td>0.393607</td>\n",
       "      <td>1.360801</td>\n",
       "      <td>1.043867</td>\n",
       "      <td>-0.488506</td>\n",
       "      <td>0.626306</td>\n",
       "      <td>0.175778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>0.671494</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>-0.003352</td>\n",
       "      <td>0.113593</td>\n",
       "      <td>0.884864</td>\n",
       "      <td>0.297531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>-0.598849</td>\n",
       "      <td>-0.084151</td>\n",
       "      <td>1.090041</td>\n",
       "      <td>0.654874</td>\n",
       "      <td>-0.112433</td>\n",
       "      <td>2.817817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25756</th>\n",
       "      <td>-0.281263</td>\n",
       "      <td>-0.084151</td>\n",
       "      <td>-1.357164</td>\n",
       "      <td>0.040611</td>\n",
       "      <td>0.737116</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>-0.281263</td>\n",
       "      <td>-0.084151</td>\n",
       "      <td>0.258914</td>\n",
       "      <td>0.399438</td>\n",
       "      <td>1.623602</td>\n",
       "      <td>-0.993051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38924</th>\n",
       "      <td>-0.320961</td>\n",
       "      <td>1.764609</td>\n",
       "      <td>0.074220</td>\n",
       "      <td>0.971128</td>\n",
       "      <td>0.392864</td>\n",
       "      <td>-0.420812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>0.076021</td>\n",
       "      <td>1.983541</td>\n",
       "      <td>0.181343</td>\n",
       "      <td>0.958965</td>\n",
       "      <td>-0.038559</td>\n",
       "      <td>2.379506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23\n",
       "24147   0.949382  -0.716622   0.028046  -0.616225   0.737116  -0.993051\n",
       "19820   0.552400  -0.473364  -1.818901  -0.008043  -1.922341   0.224479\n",
       "14798   0.076021  -0.473364  -0.433691  -0.920315  -1.527855  -0.420812\n",
       "40020   0.393607   1.360801   1.043867  -0.488506   0.626306   0.175778\n",
       "6161    0.671494   0.154242  -0.003352   0.113593   0.884864   0.297531\n",
       "...          ...        ...        ...        ...        ...        ...\n",
       "5865   -0.598849  -0.084151   1.090041   0.654874  -0.112433   2.817817\n",
       "25756  -0.281263  -0.084151  -1.357164   0.040611   0.737116  -0.993051\n",
       "4913   -0.281263  -0.084151   0.258914   0.399438   1.623602  -0.993051\n",
       "38924  -0.320961   1.764609   0.074220   0.971128   0.392864  -0.420812\n",
       "6699    0.076021   1.983541   0.181343   0.958965  -0.038559   2.379506\n",
       "\n",
       "[7000 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94292cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11355</th>\n",
       "      <td>0.076021</td>\n",
       "      <td>2.046788</td>\n",
       "      <td>0.674478</td>\n",
       "      <td>0.569729</td>\n",
       "      <td>0.183063</td>\n",
       "      <td>2.513434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>0.842991</td>\n",
       "      <td>-0.487959</td>\n",
       "      <td>0.674478</td>\n",
       "      <td>-0.920315</td>\n",
       "      <td>0.552432</td>\n",
       "      <td>-0.487776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33655</th>\n",
       "      <td>1.346364</td>\n",
       "      <td>-0.473364</td>\n",
       "      <td>0.526722</td>\n",
       "      <td>-0.677043</td>\n",
       "      <td>-0.415315</td>\n",
       "      <td>-0.280796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35348</th>\n",
       "      <td>-1.829494</td>\n",
       "      <td>1.302419</td>\n",
       "      <td>-0.742131</td>\n",
       "      <td>-0.160089</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>0.224479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>0.512701</td>\n",
       "      <td>-0.507420</td>\n",
       "      <td>0.766825</td>\n",
       "      <td>0.472420</td>\n",
       "      <td>-0.543856</td>\n",
       "      <td>1.356781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11195</th>\n",
       "      <td>0.750891</td>\n",
       "      <td>-0.084151</td>\n",
       "      <td>-1.418113</td>\n",
       "      <td>1.579309</td>\n",
       "      <td>0.097369</td>\n",
       "      <td>1.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>1.425761</td>\n",
       "      <td>-0.716622</td>\n",
       "      <td>-1.495685</td>\n",
       "      <td>-0.658797</td>\n",
       "      <td>-1.774593</td>\n",
       "      <td>-0.250358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18114</th>\n",
       "      <td>0.103016</td>\n",
       "      <td>-0.487959</td>\n",
       "      <td>-0.479864</td>\n",
       "      <td>-0.658797</td>\n",
       "      <td>-1.331350</td>\n",
       "      <td>-0.134692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17887</th>\n",
       "      <td>0.103016</td>\n",
       "      <td>-0.487959</td>\n",
       "      <td>-0.756906</td>\n",
       "      <td>-0.415525</td>\n",
       "      <td>-0.987098</td>\n",
       "      <td>-0.706931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>0.842991</td>\n",
       "      <td>-0.487959</td>\n",
       "      <td>1.782646</td>\n",
       "      <td>-0.920315</td>\n",
       "      <td>1.143422</td>\n",
       "      <td>-0.731282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23\n",
       "11355   0.076021   2.046788   0.674478   0.569729   0.183063   2.513434\n",
       "3077    0.842991  -0.487959   0.674478  -0.920315   0.552432  -0.487776\n",
       "33655   1.346364  -0.473364   0.526722  -0.677043  -0.415315  -0.280796\n",
       "35348  -1.829494   1.302419  -0.742131  -0.160089  -0.001622   0.224479\n",
       "21571   0.512701  -0.507420   0.766825   0.472420  -0.543856   1.356781\n",
       "...          ...        ...        ...        ...        ...        ...\n",
       "11195   0.750891  -0.084151  -1.418113   1.579309   0.097369   1.015873\n",
       "14000   1.425761  -0.716622  -1.495685  -0.658797  -1.774593  -0.250358\n",
       "18114   0.103016  -0.487959  -0.479864  -0.658797  -1.331350  -0.134692\n",
       "17887   0.103016  -0.487959  -0.756906  -0.415525  -0.987098  -0.706931\n",
       "2532    0.842991  -0.487959   1.782646  -0.920315   1.143422  -0.731282\n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2a0b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24147    sitting\n",
       "19820      lying\n",
       "14798      lying\n",
       "40020    walking\n",
       "6161     cycling\n",
       "          ...   \n",
       "5865     cycling\n",
       "25756    sitting\n",
       "4913     bending\n",
       "38924    walking\n",
       "6699     cycling\n",
       "Name: label, Length: 7000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aa8b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11355     cycling\n",
       "3077      bending\n",
       "33655    standing\n",
       "35348     walking\n",
       "21571     sitting\n",
       "           ...   \n",
       "11195     cycling\n",
       "14000       lying\n",
       "18114       lying\n",
       "17887       lying\n",
       "2532      bending\n",
       "Name: label, Length: 3000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576052e",
   "metadata": {},
   "source": [
    "## In activity recognition applications, correctly identifying both positive and negative instances is important. However, depending on the problem, the cost of false positives and false negatives may not be equal. For example, in medical diagnosis, a false negative (not detecting a disease when it's present) may be more costly than a false positive (detecting a disease when it's not present).\n",
    "\n",
    "## In the case of activity recognition, it's important to minimize false negatives (i.e., failing to detect an activity that's actually being performed) in order to ensure accurate tracking of physical activity levels. Failing to detect certain activities could lead to inaccurate assessment of the user's overall physical activity, which could have negative impacts on healthcare decision-making and outcomes.\n",
    "\n",
    "## F1 score takes both precision and recall into account, making it a suitable metric for evaluating performance in the case of imbalanced datasets, as well as situations where false negatives are particularly costly. By focusing on both precision and recall, F1 score provides a balanced evaluation of the model's ability to correctly classify both positive and negative instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020e1f0",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cb8a8",
   "metadata": {},
   "source": [
    "### Random Search with CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ca66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'saga', 'penalty': 'l2', 'max_iter': 200, 'fit_intercept': True, 'class_weight': 'balanced', 'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Define the hyperparameter space for random search\n",
    "random_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.1, 0.5, 1, 2, 5],\n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter': [100, 200, 500, 1000],\n",
    "}\n",
    "\n",
    "# Perform random search to find the best hyperparameters\n",
    "logreg_random = RandomizedSearchCV(estimator=logreg, param_distributions=random_grid, n_iter=100, cv=5, random_state=42,\n",
    "                              n_jobs =-1, scoring = 'f1')\n",
    "logreg_random.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(logreg_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faaa05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1123, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1261, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 210, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.6533333333333333\n",
      "Precision: 0.6441709707166171\n",
      "Recall: 0.6533333333333333\n",
      "F1 score: 0.6470794504468896\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter space for grid search\n",
    "param_grid = {\n",
    "    'penalty': [logreg_random.best_params_['penalty']],\n",
    "    'C': [0.1, 0.01, 1],\n",
    "    'fit_intercept': [logreg_random.best_params_['fit_intercept']],\n",
    "    'class_weight': [logreg_random.best_params_['class_weight']],\n",
    "    'solver': [logreg_random.best_params_['solver']],\n",
    "    'max_iter': [logreg_random.best_params_['max_iter'] + 10, logreg_random.best_params_['max_iter'] - 10 ],\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "logreg_grid = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring = 'f1')\n",
    "logreg_grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(logreg_grid.best_params_)\n",
    "\n",
    "# Fit the model with the best hyperparameters\n",
    "logreg_best = LogisticRegression(**logreg_grid.best_params_)\n",
    "logreg_best.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred = logreg_best.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27d2c77",
   "metadata": {},
   "source": [
    "## Since, this is a multiclassification problem, TP, TF and FN are calculated based on Sum of diagonal values, Sum of vertical values and Sum of horizontal values of confusion matrix respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42b4ef20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[328,  11,  14,  68,   6,   2],\n",
       "       [ 27, 307,   1,  29,   4, 149],\n",
       "       [ 11,   1, 446,  10,  44,   0],\n",
       "       [ 86,  16,  85, 210, 145,   3],\n",
       "       [  0,   4,  43, 125, 323,   1],\n",
       "       [  1, 149,   0,   5,   0, 346]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e75c6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a dataframe\n",
    "metrics = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression'],\n",
    "    'Accuracy': [accuracy],\n",
    "    'Precision': [precision],\n",
    "    'Recall': [recall],\n",
    "    'F1 Score': [f1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8074465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.644171</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.647079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression  0.653333   0.644171  0.653333  0.647079"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd0503",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd357275",
   "metadata": {},
   "source": [
    "### Random Search with CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4596a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 72 is smaller than n_iter=100. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search best params: {'kernel': 'linear', 'gamma': 'scale', 'degree': 2, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter distribution for random search\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'poly', 'rbf'],\n",
    "              'gamma': ['scale', 'auto'],\n",
    "              'degree': [2, 3, 4]}\n",
    "\n",
    "# Create an SVM classifier object\n",
    "svm = SVC()\n",
    "\n",
    "# Perform random search\n",
    "random_search = RandomizedSearchCV(svm, param_distributions=param_grid, n_iter=100, cv=5, random_state=42, n_jobs = -1,\n",
    "                                  scoring= 'f1')\n",
    "random_search.fit(x_train, y_train)\n",
    "print('Random search best params:', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58430ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [95, 105], 'degree': [1, 2, 3], 'gamma': ['auto'],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid to search with the best parameters\n",
    "param_grid_best = {\n",
    "    'C': [95,105],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'degree': [1,2,3],\n",
    "    'gamma': ['auto']\n",
    "}\n",
    "\n",
    "# Perform grid search with the best parameters\n",
    "grid_search = GridSearchCV(svm, param_grid=param_grid_best, cv=5, scoring = 'f1', n_jobs = -1)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14be8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8eedf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=95, degree=1, gamma='auto', kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(svm_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0001bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_best.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "f1 = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4d8dad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[324,  11,  13,  68,   8,   5],\n",
       "       [ 24, 308,   2,  24,   3, 156],\n",
       "       [ 14,   2, 445,   5,  46,   0],\n",
       "       [ 66,  20,  85, 210, 161,   3],\n",
       "       [  0,   9,  42, 101, 344,   0],\n",
       "       [  1, 148,   1,   2,   0, 349]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76a4ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.loc[1] = ['SVM', accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ac1cf26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.644171</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.647079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.651606</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.653039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression  0.653333   0.644171  0.653333  0.647079\n",
       "1                  SVM  0.660000   0.651606  0.660000  0.653039"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0b5da",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1233e93",
   "metadata": {},
   "source": [
    "### Random Search with CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd42b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by random search: {'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 32, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search with random search\n",
    "param_grid_random = {\n",
    "    'max_depth': [20, 24, 28, 32, 36, 40, 44, 48],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Create a decision tree model\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Run random search cv\n",
    "random_search = RandomizedSearchCV(tree, param_distributions=param_grid_random, n_iter=100, cv=5, n_jobs=-1, \n",
    "                                   scoring = 'f1')\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found by random search:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a095248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search: {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 9, 'min_samples_split': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search with grid search using the best parameters from random search\n",
    "param_grid_best = {\n",
    "    'max_depth': [random_search.best_params_['max_depth']-1, random_search.best_params_['max_depth'], random_search.best_params_['max_depth']+1],\n",
    "    'max_features': [random_search.best_params_['max_features']],\n",
    "    'min_samples_split': [random_search.best_params_['min_samples_split']+3, random_search.best_params_['min_samples_split'], random_search.best_params_['min_samples_split']+1],\n",
    "    'min_samples_leaf': [random_search.best_params_['min_samples_leaf']-1, random_search.best_params_['min_samples_leaf'], random_search.best_params_['min_samples_leaf']+1],\n",
    "    'criterion': [random_search.best_params_['criterion']]\n",
    "}\n",
    "\n",
    "# Perform grid search using the best parameters from random search\n",
    "grid_search = GridSearchCV(tree, param_grid=param_grid_best, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found by grid search:\", grid_search.best_params_)\n",
    "\n",
    "# Get the predicted values for the test set using the best model\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "f1 = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c4da496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[344,  11,   6,  51,  10,   7],\n",
       "       [ 10, 330,   0,  17,   7, 153],\n",
       "       [  4,   3, 472,  19,  14,   0],\n",
       "       [ 31,  25,  17, 330, 132,  10],\n",
       "       [  9,  20,  31, 113, 321,   2],\n",
       "       [  1, 144,   1,   6,   2, 347]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56277d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\AppData\\Local\\Temp\\ipykernel_36080\\408668432.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({\n"
     ]
    }
   ],
   "source": [
    "# Add the metrics to the dataframe\n",
    "metrics = metrics.append({\n",
    "    'Model': 'Decision Tree',\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc6d4cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.644171</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.647079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.651606</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.653039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.715545</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.714838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression  0.653333   0.644171  0.653333  0.647079\n",
       "1                  SVM  0.660000   0.651606  0.660000  0.653039\n",
       "2        Decision Tree  0.714667   0.715545  0.714667  0.714838"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cdc0e0",
   "metadata": {},
   "source": [
    "## Based on the provided table, we can see the performance of three different models on the activity recognition dataset.\n",
    "\n",
    "## The decision tree model achieved an accuracy of 0.701, precision of 0.704, recall of 0.701, and F1 score of 0.701.\n",
    "\n",
    "## We can interpret these results to mean that the decision tree model correctly predicted the activity performed by the user in 70.1% of cases. The precision of 0.704 means that when the model predicted an activity, it was correct 70.4% of the time. The recall of 0.701 indicates that the model correctly identified 70.1% of all instances of a particular activity. Finally, the F1 score of 0.701 represents a weighted average of the precision and recall, which takes into account both false positives and false negatives.\n",
    "\n",
    "## Overall, the decision tree model appears to perform moderately well on the activity recognition dataset, with an F1 score that is comparable to the other two models. However, it may be worth investigating whether other models or approaches could lead to better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e90ba6",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1dca9a",
   "metadata": {},
   "source": [
    "## Weekly Assignment (Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e59b6",
   "metadata": {},
   "source": [
    "#### Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdee2589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'adam', 'max_iter': 100, 'learning_rate_init': 0.2, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50,), 'alpha': 0.7, 'activation': 'relu'}\n",
      "CPU times: total: 5.61 s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.01, 0.1, 0.2],\n",
    "    'max_iter': [100]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=70,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(x_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e8208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     bending       0.84      0.74      0.79       429\n",
      "     cycling       0.64      0.66      0.65       517\n",
      "       lying       0.79      0.92      0.85       512\n",
      "     sitting       0.53      0.34      0.42       545\n",
      "    standing       0.61      0.80      0.69       496\n",
      "     walking       0.71      0.70      0.71       501\n",
      "\n",
      "    accuracy                           0.69      3000\n",
      "   macro avg       0.69      0.69      0.68      3000\n",
      "weighted avg       0.68      0.69      0.68      3000\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 60 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513786f1",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa87024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'alpha': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 1000, 'solver': 'adam'}\n",
      "CPU times: total: 4.77 s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"f1\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,)],\n",
    "    'activation': ['logistic'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(x_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a654fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     bending       0.80      0.76      0.78       429\n",
      "     cycling       0.68      0.51      0.58       517\n",
      "       lying       0.76      0.87      0.81       512\n",
      "     sitting       0.53      0.33      0.41       545\n",
      "    standing       0.59      0.77      0.66       496\n",
      "     walking       0.65      0.81      0.72       501\n",
      "\n",
      "    accuracy                           0.67      3000\n",
      "   macro avg       0.67      0.68      0.66      3000\n",
      "weighted avg       0.66      0.67      0.65      3000\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 42.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b22078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "736fdffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6548248998592462"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa47bc9",
   "metadata": {},
   "source": [
    "## Assignment 2 - Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c4c97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16c64f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ed9de12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331eeb68",
   "metadata": {},
   "source": [
    "## Keras - Deep Network\n",
    "\n",
    "## The below code utilses RandomSearchCV with custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e455afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 1.0554 - val_loss: 0.8071\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.7609 - val_loss: 0.7542\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.7185 - val_loss: 0.7067\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6892 - val_loss: 0.6951\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6752 - val_loss: 0.6783\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6626 - val_loss: 0.6734\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6498 - val_loss: 0.6614\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6429 - val_loss: 0.6629\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6355 - val_loss: 0.6465\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6612\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6231 - val_loss: 0.6416\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6179 - val_loss: 0.6363\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6409\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6104 - val_loss: 0.6354\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6063 - val_loss: 0.6408\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.6318\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6353\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6296\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.5900 - val_loss: 0.6218\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.5866 - val_loss: 0.6313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def f1_score_macro(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(6,)))  # Change the input shape to match your data\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax')) # final layer, 6 categories\n",
    "\n",
    "\n",
    "# Create a wrapper function for the F1Score metric that can be pickled\n",
    "def f1_score_wrapper(y_true, y_pred):\n",
    "    f1_score_metric = F1Score()\n",
    "    f1_score_metric.update_state(y_true, y_pred)\n",
    "    return f1_score_metric.result().numpy()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train_encoded, num_classes=6)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test_encoded, num_classes=6)\n",
    "\n",
    "history = model.fit(x_train, y_train_encoded, batch_size=32, epochs=20, validation_data=(x_test, y_test_encoded))\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(tf.keras.layers.Input(shape=6))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        ann.add(tf.keras.layers.Dense(hidden_layer_size, kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                                      bias_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        ann.add(tf.keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "    ann.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return ann\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    build_fn=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout=0.0\n",
    ")\n",
    "\n",
    "# Add your param_distributions dictionary as 'params'\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, )],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 40, 60],\n",
    "    'epochs':[10, 50],\n",
    "    'optimizer':['adam','sgd']\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring=make_scorer(f1_score_macro, greater_is_better=True), n_iter=20, cv=5,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(2500) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(x_train, y_train_encoded, callbacks=callback, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f4604b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.005,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (90,),\n",
       " 'model__dropout': 0.1,\n",
       " 'epochs': 50,\n",
       " 'batch_size': 20}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98494fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.005, 'optimizer': 'sgd', 'model__hidden_layer_sizes': (90,), 'model__dropout': 0.1, 'epochs': 50, 'batch_size': 20}\n",
      "150/150 [==============================] - 0s 746us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       429\n",
      "           1       0.66      0.65      0.66       517\n",
      "           2       0.85      0.93      0.89       512\n",
      "           3       0.60      0.52      0.56       545\n",
      "           4       0.68      0.78      0.73       496\n",
      "           5       0.69      0.73      0.71       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.73      3000\n",
      "   macro avg       0.73      0.73      0.73      3000\n",
      "weighted avg       0.73      0.72      0.72      3000\n",
      " samples avg       0.72      0.72      0.72      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)\n",
    "y_pred = best_net.predict(x_test)\n",
    "print(classification_report(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97fc6bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7312588582362869\n",
      "Recall: 0.7285275092494019\n",
      "F1-score: 0.7273203372977227\n",
      "Accuracy: 0.7146666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels = encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_labels, average='macro')\n",
    "recall = recall_score(y_test, y_pred_labels, average='macro')\n",
    "f1 = f1_score(y_test, y_pred_labels, average='macro')\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f10e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuv1\\AppData\\Local\\Temp\\ipykernel_36080\\2026662319.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics = metrics.append({\n"
     ]
    }
   ],
   "source": [
    "metrics = metrics.append({\n",
    "    'Model': 'Deep Neural Network',\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ba527a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.644171</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.647079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.651606</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.653039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.715545</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.714838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.728528</td>\n",
       "      <td>0.727320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  Logistic Regression  0.653333   0.644171  0.653333  0.647079\n",
       "1                  SVM  0.660000   0.651606  0.660000  0.653039\n",
       "2        Decision Tree  0.714667   0.715545  0.714667  0.714838\n",
       "3  Deep Neural Network  0.714667   0.731259  0.728528  0.727320"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea194a",
   "metadata": {},
   "source": [
    "## The assessment of the models based on their F1 scores indicated that the Neural Network Keras DNN model achieved the highest score of 0.7273, followed by the Decision Tree model with an F1 score of 0.7148. The SVM model obtained an F1 score of 0.6530, while the Logistic Regression model received the lowest F1 score of 0.6471.\n",
    "\n",
    "## The Neural Network Keras DNN model is a deep learning model that can identify complex relationships between features in the data, making it suitable for large datasets. The Decision Tree model is a non-parametric model that can interpret both categorical and continuous data easily. The SVM model is a powerful model that can handle high-dimensional data and is effective in both linear and non-linear classification tasks. The Logistic Regression model is a linear model that is commonly used as a benchmark for classification tasks.\n",
    "\n",
    "## To summarize, the Neural Network Keras DNN model is the best choice for making predictions based on its superior F1 score, while the Decision Tree model is also a good alternative. However, the SVM and Logistic Regression models may not perform as well as the other models in certain scenarios due to their lower F1 scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
